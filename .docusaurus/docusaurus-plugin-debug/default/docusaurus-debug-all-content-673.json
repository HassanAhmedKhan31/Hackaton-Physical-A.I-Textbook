{
  "docusaurus-plugin-content-docs": {
    "default": {
      "loadedVersions": [
        {
          "versionName": "current",
          "label": "Next",
          "banner": null,
          "badge": false,
          "noIndex": false,
          "className": "docs-version-current",
          "path": "/",
          "tagsPath": "/tags",
          "isLast": true,
          "routePriority": -1,
          "sidebarFilePath": "C:\\Users\\Hassan Ahmed Khan\\Desktop\\my-ai-book\\sidebars.js",
          "contentPath": "C:\\Users\\Hassan Ahmed Khan\\Desktop\\my-ai-book\\docs",
          "contentPathLocalized": "C:\\Users\\Hassan Ahmed Khan\\Desktop\\my-ai-book\\i18n\\en\\docusaurus-plugin-content-docs\\current",
          "docs": [
            {
              "id": "module-1/intro-nervous-system",
              "title": "The Nervous System of the Robot",
              "description": "<PersonalizedContent",
              "source": "@site/docs/module-1/01-intro-nervous-system.md",
              "sourceDirName": "module-1",
              "slug": "/module-1/intro-nervous-system",
              "permalink": "/module-1/intro-nervous-system",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 1,
              "frontMatter": {
                "sidebar_position": 1,
                "title": "The Nervous System of the Robot"
              },
              "sidebar": "tutorialSidebar",
              "next": {
                "title": "Neurons & Nodes",
                "permalink": "/module-1/nodes-and-rclpy"
              }
            },
            {
              "id": "module-1/nodes-and-rclpy",
              "title": "Neurons & Nodes",
              "description": "In the biological analogy, a Node is a neuron or a cluster of neurons dedicated to a single task. In ROS 2 terms, a Node is a single executable process—a Python script—that performs computation.",
              "source": "@site/docs/module-1/02-nodes-and-rclpy.md",
              "sourceDirName": "module-1",
              "slug": "/module-1/nodes-and-rclpy",
              "permalink": "/module-1/nodes-and-rclpy",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 2,
              "frontMatter": {
                "sidebar_position": 2,
                "title": "Neurons & Nodes"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "The Nervous System of the Robot",
                "permalink": "/module-1/intro-nervous-system"
              },
              "next": {
                "title": "Signals & Synapses (Topics)",
                "permalink": "/module-1/topics-and-messages"
              }
            },
            {
              "id": "module-1/services-actions",
              "title": "Reflexes & Requests (Services)",
              "description": "Topics are great for continuous data (sensor streams, heartbeats), like listening to a radio. But sometimes you need to ask a specific question and get a specific answer.",
              "source": "@site/docs/module-1/04-services-actions.md",
              "sourceDirName": "module-1",
              "slug": "/module-1/services-actions",
              "permalink": "/module-1/services-actions",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 4,
              "frontMatter": {
                "sidebar_position": 4,
                "title": "Reflexes & Requests (Services)"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Signals & Synapses (Topics)",
                "permalink": "/module-1/topics-and-messages"
              },
              "next": {
                "title": "The Body Schema (URDF)",
                "permalink": "/module-1/urdf-humanoid-body"
              }
            },
            {
              "id": "module-1/topics-and-messages",
              "title": "Signals & Synapses (Topics)",
              "description": "If Nodes are neurons, Topics are the synapses—the gaps where signals jump from one neuron to another.",
              "source": "@site/docs/module-1/03-topics-and-messages.md",
              "sourceDirName": "module-1",
              "slug": "/module-1/topics-and-messages",
              "permalink": "/module-1/topics-and-messages",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 3,
              "frontMatter": {
                "sidebar_position": 3,
                "title": "Signals & Synapses (Topics)"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Neurons & Nodes",
                "permalink": "/module-1/nodes-and-rclpy"
              },
              "next": {
                "title": "Reflexes & Requests (Services)",
                "permalink": "/module-1/services-actions"
              }
            },
            {
              "id": "module-1/urdf-humanoid-body",
              "title": "The Body Schema (URDF)",
              "description": "A nervous system is useless without a body. In ROS 2, the robot's physical structure is defined by the Unified Robot Description Format (URDF). This is an XML file that tells the robot:",
              "source": "@site/docs/module-1/05-urdf-humanoid-body.md",
              "sourceDirName": "module-1",
              "slug": "/module-1/urdf-humanoid-body",
              "permalink": "/module-1/urdf-humanoid-body",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 5,
              "frontMatter": {
                "sidebar_position": 5,
                "title": "The Body Schema (URDF)"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Reflexes & Requests (Services)",
                "permalink": "/module-1/services-actions"
              },
              "next": {
                "title": "The Workspace (The Robot's Home)",
                "permalink": "/module-2/workspaces-and-packages"
              }
            },
            {
              "id": "module-2/actions",
              "title": "Long-Running Tasks (Actions)",
              "description": "In Module 1, we learned about Services (Request -> Response). Services are like a function call: you ask for something, and you wait until you get the answer. This works great for \"Turn on LED\" or \"Get Battery Level.\"",
              "source": "@site/docs/module-2/04-actions.md",
              "sourceDirName": "module-2",
              "slug": "/module-2/actions",
              "permalink": "/module-2/actions",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 4,
              "frontMatter": {
                "sidebar_position": 4,
                "title": "Long-Running Tasks (Actions)"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Runtime Configuration (Parameters)",
                "permalink": "/module-2/parameters"
              },
              "next": {
                "title": "Defining the Protocol (Messages)",
                "permalink": "/module-2/custom-interfaces"
              }
            },
            {
              "id": "module-2/custom-interfaces",
              "title": "Defining the Protocol (Messages)",
              "description": "In any language, you need words to communicate. If you want to talk about \"Philosophy,\" you need complex words. If you want to talk about \"Rocket Science,\" you need specific technical terms.",
              "source": "@site/docs/module-2/05-custom-interfaces.md",
              "sourceDirName": "module-2",
              "slug": "/module-2/custom-interfaces",
              "permalink": "/module-2/custom-interfaces",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 5,
              "frontMatter": {
                "sidebar_position": 5,
                "title": "Defining the Protocol (Messages)"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Long-Running Tasks (Actions)",
                "permalink": "/module-2/actions"
              },
              "next": {
                "title": "The Simulation Lab (Setting up Gazebo)",
                "permalink": "/module-3/gazebo-environment"
              }
            },
            {
              "id": "module-2/launch-files",
              "title": "Launch Systems (Waking Up the Robot)",
              "description": "A humanoid robot has many distinct parts: vision, balance, motor control, path planning, and voice recognition. If each of these is a separate Node (as they should be), starting them manually would be a nightmare. You would need to open 20 terminal tabs and type 20 commands every time you turned the robot on.",
              "source": "@site/docs/module-2/02-launch-files.md",
              "sourceDirName": "module-2",
              "slug": "/module-2/launch-files",
              "permalink": "/module-2/launch-files",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 2,
              "frontMatter": {
                "sidebar_position": 2,
                "title": "Launch Systems (Waking Up the Robot)"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "The Workspace (The Robot's Home)",
                "permalink": "/module-2/workspaces-and-packages"
              },
              "next": {
                "title": "Runtime Configuration (Parameters)",
                "permalink": "/module-2/parameters"
              }
            },
            {
              "id": "module-2/parameters",
              "title": "Runtime Configuration (Parameters)",
              "description": "Hard-coding values is a bad habit in software engineering. If you hard-code your robot's walking speed to 1.0 m/s, you have to stop the robot, edit the code, rebuild, and restart just to test 0.5 m/s.",
              "source": "@site/docs/module-2/03-parameters.md",
              "sourceDirName": "module-2",
              "slug": "/module-2/parameters",
              "permalink": "/module-2/parameters",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 3,
              "frontMatter": {
                "sidebar_position": 3,
                "title": "Runtime Configuration (Parameters)"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Launch Systems (Waking Up the Robot)",
                "permalink": "/module-2/launch-files"
              },
              "next": {
                "title": "Long-Running Tasks (Actions)",
                "permalink": "/module-2/actions"
              }
            },
            {
              "id": "module-2/workspaces-and-packages",
              "title": "The Workspace (The Robot's Home)",
              "description": "Before we start building the brain of our humanoid, we need a place to work. In ROS 2, this is called a Workspace.",
              "source": "@site/docs/module-2/01-workspaces-and-packages.md",
              "sourceDirName": "module-2",
              "slug": "/module-2/workspaces-and-packages",
              "permalink": "/module-2/workspaces-and-packages",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 1,
              "frontMatter": {
                "sidebar_position": 1,
                "title": "The Workspace (The Robot's Home)"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "The Body Schema (URDF)",
                "permalink": "/module-1/urdf-humanoid-body"
              },
              "next": {
                "title": "Launch Systems (Waking Up the Robot)",
                "permalink": "/module-2/launch-files"
              }
            },
            {
              "id": "module-3/gazebo-environment",
              "title": "The Simulation Lab (Setting up Gazebo)",
              "description": "Welcome to the Matrix.",
              "source": "@site/docs/module-3/01-gazebo-environment.md",
              "sourceDirName": "module-3",
              "slug": "/module-3/gazebo-environment",
              "permalink": "/module-3/gazebo-environment",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 1,
              "frontMatter": {
                "sidebar_position": 1,
                "title": "The Simulation Lab (Setting up Gazebo)"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Defining the Protocol (Messages)",
                "permalink": "/module-2/custom-interfaces"
              },
              "next": {
                "title": "The Format War (URDF vs. SDF)",
                "permalink": "/module-3/urdf-vs-sdf"
              }
            },
            {
              "id": "module-3/physics-and-worlds",
              "title": "Building the World",
              "description": "Before we spawn our robot, we need a world for it to live in. In Gazebo, the world is defined using an SDF file.",
              "source": "@site/docs/module-3/03-physics-and-worlds.md",
              "sourceDirName": "module-3",
              "slug": "/module-3/physics-and-worlds",
              "permalink": "/module-3/physics-and-worlds",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 3,
              "frontMatter": {
                "sidebar_position": 3,
                "title": "Building the World"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "The Format War (URDF vs. SDF)",
                "permalink": "/module-3/urdf-vs-sdf"
              },
              "next": {
                "title": "Virtual Eyes & Ears (Sensors)",
                "permalink": "/module-3/simulating-sensors"
              }
            },
            {
              "id": "module-3/simulating-sensors",
              "title": "Virtual Eyes & Ears (Sensors)",
              "description": "A simulation is only useful if the robot can perceive it. If we want to test our navigation algorithms, our simulated robot needs a simulated Lidar.",
              "source": "@site/docs/module-3/04-simulating-sensors.md",
              "sourceDirName": "module-3",
              "slug": "/module-3/simulating-sensors",
              "permalink": "/module-3/simulating-sensors",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 4,
              "frontMatter": {
                "sidebar_position": 4,
                "title": "Virtual Eyes & Ears (Sensors)"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Building the World",
                "permalink": "/module-3/physics-and-worlds"
              },
              "next": {
                "title": "The Pretty Face (Unity Visualization)",
                "permalink": "/module-3/unity-visualization"
              }
            },
            {
              "id": "module-3/unity-visualization",
              "title": "The Pretty Face (Unity Visualization)",
              "description": "Gazebo is a scientific tool. Its graphics are \"good enough\" for debugging, but they aren't beautiful.",
              "source": "@site/docs/module-3/05-unity-visualization.md",
              "sourceDirName": "module-3",
              "slug": "/module-3/unity-visualization",
              "permalink": "/module-3/unity-visualization",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 5,
              "frontMatter": {
                "sidebar_position": 5,
                "title": "The Pretty Face (Unity Visualization)"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Virtual Eyes & Ears (Sensors)",
                "permalink": "/module-3/simulating-sensors"
              },
              "next": {
                "title": "The Omniverse (Isaac Sim)",
                "permalink": "/module-4/isaac-sim-omniverse"
              }
            },
            {
              "id": "module-3/urdf-vs-sdf",
              "title": "The Format War (URDF vs. SDF)",
              "description": "As a roboticist, you are caught in a format war between two giants: ROS and Gazebo.",
              "source": "@site/docs/module-3/02-urdf-vs-sdf.md",
              "sourceDirName": "module-3",
              "slug": "/module-3/urdf-vs-sdf",
              "permalink": "/module-3/urdf-vs-sdf",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 2,
              "frontMatter": {
                "sidebar_position": 2,
                "title": "The Format War (URDF vs. SDF)"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "The Simulation Lab (Setting up Gazebo)",
                "permalink": "/module-3/gazebo-environment"
              },
              "next": {
                "title": "Building the World",
                "permalink": "/module-3/physics-and-worlds"
              }
            },
            {
              "id": "module-4/isaac-ros-gems",
              "title": "Supercharging ROS (Isaac ROS GEMs)",
              "description": "Standard ROS 2 nodes often struggle with high-bandwidth data like 4K video streams or point clouds because they process data on the CPU. Isaac ROS GEMs are a collection of GPU-accelerated packages that replace these slow standard nodes.",
              "source": "@site/docs/module-4/02-isaac-ros-gems.md",
              "sourceDirName": "module-4",
              "slug": "/module-4/isaac-ros-gems",
              "permalink": "/module-4/isaac-ros-gems",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 2,
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "The Omniverse (Isaac Sim)",
                "permalink": "/module-4/isaac-sim-omniverse"
              },
              "next": {
                "title": "Spatial Awareness (VSLAM & Nav2)",
                "permalink": "/module-4/nav2-and-vslam"
              }
            },
            {
              "id": "module-4/isaac-sim-omniverse",
              "title": "The Omniverse (Isaac Sim)",
              "description": "Welcome to the cutting edge of robotics simulation. In previous modules, we used Gazebo, which relies primarily on your CPU for physics calculations. Now, we are stepping into NVIDIA Isaac Sim, a photo-realistic, physically accurate virtual environment powered by NVIDIA Omniverse.",
              "source": "@site/docs/module-4/01-isaac-sim-omniverse.md",
              "sourceDirName": "module-4",
              "slug": "/module-4/isaac-sim-omniverse",
              "permalink": "/module-4/isaac-sim-omniverse",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 1,
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "The Pretty Face (Unity Visualization)",
                "permalink": "/module-3/unity-visualization"
              },
              "next": {
                "title": "Supercharging ROS (Isaac ROS GEMs)",
                "permalink": "/module-4/isaac-ros-gems"
              }
            },
            {
              "id": "module-4/nav2-and-vslam",
              "title": "Spatial Awareness (VSLAM & Nav2)",
              "description": "For a humanoid robot to be useful, it must answer two questions: \"Where am I?\" and \"How do I get there?\" In this section, we replace traditional Lidar-based SLAM with Visual SLAM using Isaac ROS.",
              "source": "@site/docs/module-4/03-nav2-and-vslam.md",
              "sourceDirName": "module-4",
              "slug": "/module-4/nav2-and-vslam",
              "permalink": "/module-4/nav2-and-vslam",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 3,
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Supercharging ROS (Isaac ROS GEMs)",
                "permalink": "/module-4/isaac-ros-gems"
              },
              "next": {
                "title": "Training the Brain (Synthetic Data)",
                "permalink": "/module-4/synthetic-data-generation"
              }
            },
            {
              "id": "module-4/rl-and-sim-to-real",
              "title": "Walking with AI (Reinforcement Learning)",
              "description": "Classical robotics uses explicit mathematical equations (Inverse Kinematics) to calculate how a robot should move. However, for complex tasks like humanoid walking, the math becomes incredibly difficult.",
              "source": "@site/docs/module-4/05-rl-and-sim-to-real.md",
              "sourceDirName": "module-4",
              "slug": "/module-4/rl-and-sim-to-real",
              "permalink": "/module-4/rl-and-sim-to-real",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 5,
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Training the Brain (Synthetic Data)",
                "permalink": "/module-4/synthetic-data-generation"
              },
              "next": {
                "title": "The Math of Movement (Kinematics)",
                "permalink": "/module-5/kinematics-dynamics"
              }
            },
            {
              "id": "module-4/synthetic-data-generation",
              "title": "Training the Brain (Synthetic Data)",
              "description": "Training modern AI models (like Object Detection or Segmentation) requires massive datasets—often tens of thousands of labeled images. Collecting this data in the real world is slow, expensive, and sometimes dangerous.",
              "source": "@site/docs/module-4/04-synthetic-data-generation.md",
              "sourceDirName": "module-4",
              "slug": "/module-4/synthetic-data-generation",
              "permalink": "/module-4/synthetic-data-generation",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 4,
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Spatial Awareness (VSLAM & Nav2)",
                "permalink": "/module-4/nav2-and-vslam"
              },
              "next": {
                "title": "Walking with AI (Reinforcement Learning)",
                "permalink": "/module-4/rl-and-sim-to-real"
              }
            },
            {
              "id": "module-5/bipedal-locomotion",
              "title": "The Art of Falling (Bipedal Walking)",
              "description": "Walking is a complex feat of engineering. For a humanoid, walking is essentially a state of controlled falling. Every step is a move to catch the body before it hits the ground.",
              "source": "@site/docs/module-5/02-bipedal-locomotion.md",
              "sourceDirName": "module-5",
              "slug": "/module-5/bipedal-locomotion",
              "permalink": "/module-5/bipedal-locomotion",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 2,
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "The Math of Movement (Kinematics)",
                "permalink": "/module-5/kinematics-dynamics"
              },
              "next": {
                "title": "Grasping the World (MoveIt 2)",
                "permalink": "/module-5/manipulation-grasping"
              }
            },
            {
              "id": "module-5/capstone-integration",
              "title": "Assembling the Avatar (The Capstone)",
              "description": "In this final section of Module 5, we look at how to integrate every technology we have learned so far into a single, cohesive \"Robot Brain.\" This is the goal of the Physical AI course: creating an autonomous humanoid avatar.",
              "source": "@site/docs/module-5/05-capstone-integration.md",
              "sourceDirName": "module-5",
              "slug": "/module-5/capstone-integration",
              "permalink": "/module-5/capstone-integration",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 5,
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Social Robotics (HRI)",
                "permalink": "/module-5/human-robot-interaction"
              },
              "next": {
                "title": "The Voice Interface (VUI)",
                "permalink": "/module-6/intro-conversational-robotics"
              }
            },
            {
              "id": "module-5/human-robot-interaction",
              "title": "Social Robotics (HRI)",
              "description": "Humanoid robots are designed to operate in human environments. This means they must follow social \"rules\" that we often take for granted. This field is called Human-Robot Interaction (HRI).",
              "source": "@site/docs/module-5/04-human-robot-interaction.md",
              "sourceDirName": "module-5",
              "slug": "/module-5/human-robot-interaction",
              "permalink": "/module-5/human-robot-interaction",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 4,
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Grasping the World (MoveIt 2)",
                "permalink": "/module-5/manipulation-grasping"
              },
              "next": {
                "title": "Assembling the Avatar (The Capstone)",
                "permalink": "/module-5/capstone-integration"
              }
            },
            {
              "id": "module-5/kinematics-dynamics",
              "title": "The Math of Movement (Kinematics)",
              "description": "To make a humanoid robot move, we need to understand how its joints relate to the position of its body in 3D space. This study of motion without considering forces is called Kinematics.",
              "source": "@site/docs/module-5/01-kinematics-dynamics.md",
              "sourceDirName": "module-5",
              "slug": "/module-5/kinematics-dynamics",
              "permalink": "/module-5/kinematics-dynamics",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 1,
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Walking with AI (Reinforcement Learning)",
                "permalink": "/module-4/rl-and-sim-to-real"
              },
              "next": {
                "title": "The Art of Falling (Bipedal Walking)",
                "permalink": "/module-5/bipedal-locomotion"
              }
            },
            {
              "id": "module-5/manipulation-grasping",
              "title": "Grasping the World (MoveIt 2)",
              "description": "While the legs handle locomotion, the arms handle Manipulation. In ROS 2, the gold standard for controlling robotic arms is MoveIt 2.",
              "source": "@site/docs/module-5/03-manipulation-grasping.md",
              "sourceDirName": "module-5",
              "slug": "/module-5/manipulation-grasping",
              "permalink": "/module-5/manipulation-grasping",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 3,
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "The Art of Falling (Bipedal Walking)",
                "permalink": "/module-5/bipedal-locomotion"
              },
              "next": {
                "title": "Social Robotics (HRI)",
                "permalink": "/module-5/human-robot-interaction"
              }
            },
            {
              "id": "module-6/future-ethics",
              "title": "Living with Robots (Ethics & Future)",
              "description": "As we conclude this course, we must address the reality of releasing autonomous agents into the real world. A robot is not just a machine; it is a physical entity that shares space with humans.",
              "source": "@site/docs/module-6/05-future-ethics.md",
              "sourceDirName": "module-6",
              "slug": "/module-6/future-ethics",
              "permalink": "/module-6/future-ethics",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 5,
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Vision-Language-Action (VLA)",
                "permalink": "/module-6/multimodal-interaction"
              }
            },
            {
              "id": "module-6/hearing-with-whisper",
              "title": "The Robot's Ears (Speech Recognition)",
              "description": "The first step in interaction is hearing. We need to convert sound waves (analog air pressure) into text (digital strings). For this, we use OpenAI Whisper, a state-of-the-art Automatic Speech Recognition (ASR) system.",
              "source": "@site/docs/module-6/02-hearing-with-whisper.md",
              "sourceDirName": "module-6",
              "slug": "/module-6/hearing-with-whisper",
              "permalink": "/module-6/hearing-with-whisper",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 2,
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "The Voice Interface (VUI)",
                "permalink": "/module-6/intro-conversational-robotics"
              },
              "next": {
                "title": "The Cognitive Core (GPT Integration)",
                "permalink": "/module-6/thinking-with-llms"
              }
            },
            {
              "id": "module-6/intro-conversational-robotics",
              "title": "The Voice Interface (VUI)",
              "description": "For decades, we have controlled robots with keyboards, gamepads, and touchscreens. But if humanoids are to integrate seamlessly into our homes, they must speak our language. This is the Voice User Interface (VUI).",
              "source": "@site/docs/module-6/01-intro-conversational-robotics.md",
              "sourceDirName": "module-6",
              "slug": "/module-6/intro-conversational-robotics",
              "permalink": "/module-6/intro-conversational-robotics",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 1,
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Assembling the Avatar (The Capstone)",
                "permalink": "/module-5/capstone-integration"
              },
              "next": {
                "title": "The Robot's Ears (Speech Recognition)",
                "permalink": "/module-6/hearing-with-whisper"
              }
            },
            {
              "id": "module-6/multimodal-interaction",
              "title": "Vision-Language-Action (VLA)",
              "description": "A voice assistant like Alexa is blind. It can hear \"Turn on the lights,\" but it cannot understand \"Pick up that red cup.\" For physical interaction, we need Multimodal AI—combining Vision and Language.",
              "source": "@site/docs/module-6/04-multimodal-interaction.md",
              "sourceDirName": "module-6",
              "slug": "/module-6/multimodal-interaction",
              "permalink": "/module-6/multimodal-interaction",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 4,
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "The Cognitive Core (GPT Integration)",
                "permalink": "/module-6/thinking-with-llms"
              },
              "next": {
                "title": "Living with Robots (Ethics & Future)",
                "permalink": "/module-6/future-ethics"
              }
            },
            {
              "id": "module-6/thinking-with-llms",
              "title": "The Cognitive Core (GPT Integration)",
              "description": "Now that the robot can hear \"Move forward,\" how does it know how to move? It needs a brain to translate natural language into robot instructions. We use a Large Language Model (LLM) like GPT-4.",
              "source": "@site/docs/module-6/03-thinking-with-llms.md",
              "sourceDirName": "module-6",
              "slug": "/module-6/thinking-with-llms",
              "permalink": "/module-6/thinking-with-llms",
              "draft": false,
              "unlisted": false,
              "tags": [],
              "version": "current",
              "sidebarPosition": 3,
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "The Robot's Ears (Speech Recognition)",
                "permalink": "/module-6/hearing-with-whisper"
              },
              "next": {
                "title": "Vision-Language-Action (VLA)",
                "permalink": "/module-6/multimodal-interaction"
              }
            }
          ],
          "drafts": [],
          "sidebars": {
            "tutorialSidebar": [
              {
                "type": "category",
                "label": "Module 1: The Robotic Nervous System",
                "items": [
                  {
                    "type": "doc",
                    "id": "module-1/intro-nervous-system"
                  },
                  {
                    "type": "doc",
                    "id": "module-1/nodes-and-rclpy"
                  },
                  {
                    "type": "doc",
                    "id": "module-1/topics-and-messages"
                  },
                  {
                    "type": "doc",
                    "id": "module-1/services-actions"
                  },
                  {
                    "type": "doc",
                    "id": "module-1/urdf-humanoid-body"
                  }
                ],
                "collapsed": true,
                "collapsible": true
              },
              {
                "type": "category",
                "label": "Module 2: ROS 2 Fundamentals",
                "items": [
                  {
                    "type": "doc",
                    "id": "module-2/workspaces-and-packages"
                  },
                  {
                    "type": "doc",
                    "id": "module-2/launch-files"
                  },
                  {
                    "type": "doc",
                    "id": "module-2/parameters"
                  },
                  {
                    "type": "doc",
                    "id": "module-2/actions"
                  },
                  {
                    "type": "doc",
                    "id": "module-2/custom-interfaces"
                  }
                ],
                "collapsed": true,
                "collapsible": true
              },
              {
                "type": "category",
                "label": "Module 3: Robot Simulation",
                "items": [
                  {
                    "type": "doc",
                    "id": "module-3/gazebo-environment"
                  },
                  {
                    "type": "doc",
                    "id": "module-3/urdf-vs-sdf"
                  },
                  {
                    "type": "doc",
                    "id": "module-3/physics-and-worlds"
                  },
                  {
                    "type": "doc",
                    "id": "module-3/simulating-sensors"
                  },
                  {
                    "type": "doc",
                    "id": "module-3/unity-visualization"
                  }
                ],
                "collapsed": true,
                "collapsible": true
              },
              {
                "type": "category",
                "label": "Module 4: NVIDIA Isaac AI",
                "items": [
                  {
                    "type": "doc",
                    "id": "module-4/isaac-sim-omniverse"
                  },
                  {
                    "type": "doc",
                    "id": "module-4/isaac-ros-gems"
                  },
                  {
                    "type": "doc",
                    "id": "module-4/nav2-and-vslam"
                  },
                  {
                    "type": "doc",
                    "id": "module-4/synthetic-data-generation"
                  },
                  {
                    "type": "doc",
                    "id": "module-4/rl-and-sim-to-real"
                  }
                ],
                "collapsed": true,
                "collapsible": true
              },
              {
                "type": "category",
                "label": "Module 5: Humanoid Development",
                "items": [
                  {
                    "type": "doc",
                    "id": "module-5/kinematics-dynamics"
                  },
                  {
                    "type": "doc",
                    "id": "module-5/bipedal-locomotion"
                  },
                  {
                    "type": "doc",
                    "id": "module-5/manipulation-grasping"
                  },
                  {
                    "type": "doc",
                    "id": "module-5/human-robot-interaction"
                  },
                  {
                    "type": "doc",
                    "id": "module-5/capstone-integration"
                  }
                ],
                "collapsed": true,
                "collapsible": true
              },
              {
                "type": "category",
                "label": "Module 6: Conversational Robotics",
                "items": [
                  {
                    "type": "doc",
                    "id": "module-6/intro-conversational-robotics"
                  },
                  {
                    "type": "doc",
                    "id": "module-6/hearing-with-whisper"
                  },
                  {
                    "type": "doc",
                    "id": "module-6/thinking-with-llms"
                  },
                  {
                    "type": "doc",
                    "id": "module-6/multimodal-interaction"
                  },
                  {
                    "type": "doc",
                    "id": "module-6/future-ethics"
                  }
                ],
                "collapsed": true,
                "collapsible": true
              }
            ]
          }
        }
      ]
    }
  },
  "docusaurus-plugin-content-blog": {
    "default": {
      "blogSidebarTitle": "Recent posts",
      "blogPosts": [],
      "blogListPaginated": [],
      "blogTags": {},
      "blogTagsListPath": "/blog/tags",
      "blogTagsPaginated": []
    }
  },
  "docusaurus-plugin-content-pages": {
    "default": [
      {
        "type": "jsx",
        "permalink": "/",
        "source": "@site/src/pages/index.tsx"
      }
    ]
  },
  "docusaurus-plugin-debug": {},
  "docusaurus-theme-classic": {},
  "docusaurus-bootstrap-plugin": {},
  "docusaurus-mdx-fallback-plugin": {}
}